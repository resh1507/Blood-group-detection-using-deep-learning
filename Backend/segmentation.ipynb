{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69aeb426-6b8b-4d6a-bf22-a70f904d1a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting 24000 images...\n",
      "Processed 0/24000 images...\n",
      "Processed 500/24000 images...\n",
      "Processed 1000/24000 images...\n",
      "Processed 1500/24000 images...\n",
      "Processed 2000/24000 images...\n",
      "Processed 2500/24000 images...\n",
      "Processed 3000/24000 images...\n",
      "Processed 3500/24000 images...\n",
      "Processed 4000/24000 images...\n",
      "Processed 4500/24000 images...\n",
      "Processed 5000/24000 images...\n",
      "Processed 5500/24000 images...\n",
      "Processed 6000/24000 images...\n",
      "Processed 6500/24000 images...\n",
      "Processed 7000/24000 images...\n",
      "Processed 7500/24000 images...\n",
      "Processed 8000/24000 images...\n",
      "Processed 8500/24000 images...\n",
      "Processed 9000/24000 images...\n",
      "Processed 9500/24000 images...\n",
      "Processed 10000/24000 images...\n",
      "Processed 10500/24000 images...\n",
      "Processed 11000/24000 images...\n",
      "Processed 11500/24000 images...\n",
      "Processed 12000/24000 images...\n",
      "Processed 12500/24000 images...\n",
      "Processed 13000/24000 images...\n",
      "Processed 13500/24000 images...\n",
      "Processed 14000/24000 images...\n",
      "Processed 14500/24000 images...\n",
      "Processed 15000/24000 images...\n",
      "Processed 15500/24000 images...\n",
      "Processed 16000/24000 images...\n",
      "Processed 16500/24000 images...\n",
      "Processed 17000/24000 images...\n",
      "Processed 17500/24000 images...\n",
      "Processed 18000/24000 images...\n",
      "Processed 18500/24000 images...\n",
      "Processed 19000/24000 images...\n",
      "Processed 19500/24000 images...\n",
      "Processed 20000/24000 images...\n",
      "Processed 20500/24000 images...\n",
      "Processed 21000/24000 images...\n",
      "Processed 21500/24000 images...\n",
      "Processed 22000/24000 images...\n",
      "Processed 22500/24000 images...\n",
      "Processed 23000/24000 images...\n",
      "Processed 23500/24000 images...\n",
      "✅ Segmentation completed! Total segmented images: 24000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage\n",
    "from PIL import Image\n",
    "\n",
    "# Load augmented dataset\n",
    "X_aug = np.load(\"X_fingerprint_aug.npy\")  # Shape: (num_augmented_images, 128, 128, 1)\n",
    "y_aug = np.load(\"y_fingerprint_aug.npy\")  # Labels\n",
    "\n",
    "# Path to save segmented images\n",
    "segmented_dir = r\"D:\\segmented_data\"\n",
    "os.makedirs(segmented_dir, exist_ok=True)\n",
    "\n",
    "segmented_X = []\n",
    "\n",
    "print(f\"Segmenting {len(X_aug)} images...\")\n",
    "\n",
    "for i, img in enumerate(X_aug):\n",
    "    img = (img * 255).astype(np.uint8).squeeze()  # Convert to uint8 and remove channel dimension\n",
    "\n",
    "    # Apply Otsu's threshold\n",
    "    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Compute the distance transform\n",
    "    D = ndimage.distance_transform_edt(thresh)\n",
    "\n",
    "    # Find local maxima (new version fix)\n",
    "    coordinates = peak_local_max(D, min_distance=10, labels=thresh)\n",
    "    local_max = np.zeros_like(D, dtype=bool)\n",
    "    local_max[tuple(coordinates.T)] = True\n",
    "\n",
    "    # Perform connected component analysis\n",
    "    markers, _ = ndimage.label(local_max)\n",
    "\n",
    "    # Apply Watershed\n",
    "    labels = watershed(-D, markers, mask=thresh)\n",
    "\n",
    "    # Convert to binary mask (Segmented image)\n",
    "    segmented = np.where(labels > 0, 255, 0).astype(np.uint8)\n",
    "\n",
    "    # Save segmented image\n",
    "    segmented_X.append(segmented)\n",
    "    save_path = os.path.join(segmented_dir, f\"seg_{i}.png\")\n",
    "    Image.fromarray(segmented).save(save_path)\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        print(f\"Processed {i}/{len(X_aug)} images...\")\n",
    "\n",
    "# Convert to NumPy array and normalize\n",
    "segmented_X = np.array(segmented_X) / 255.0  # Normalize to [0,1]\n",
    "\n",
    "# Save segmented dataset\n",
    "np.save(\"X_fingerprint_segmented.npy\", segmented_X)\n",
    "np.save(\"y_fingerprint_segmented.npy\", y_aug)\n",
    "\n",
    "print(f\"✅ Segmentation completed! Total segmented images: {len(segmented_X)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fbce34-e7d3-4c91-af39-7288771fe37f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
